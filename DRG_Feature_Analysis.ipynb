{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRG Feature Analysis\n",
    "This notebook is part of the paper: Automated Segmentation of the Dorsal Root Ganglia (DRG) in MRI by Nauroth-KreÃŸ et al., 2023\n",
    "The following cells contain the code used for the calculation of DRG features with the predicted and ground truth labels. After the cells for calculations follow cells with the matching visualization code.\n",
    "\n",
    "The code is ready to use with any dataset matching the general structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "def load_files(data_dir : Path | str) -> List[nib.Nifti1Image]:\n",
    "    \"\"\"Load all nifti files in directory\n",
    "    \n",
    "    :param data_dir: Path to directory containing a set of nifti images\n",
    "    :return: Dictionary with image IDs derived from the file name as keys and nibabel.Nifti1Images as values\n",
    "    \"\"\"\n",
    "    file_paths = sorted(Path(data_dir).glob('*.nii*'))\n",
    "    imgs = {Path(path.stem).stem.split('_')[0]: nib.load(path) for path in file_paths}\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def extract_vol(limg : nib.Nifti1Image) -> Dict[int, int]:\n",
    "    \"\"\"Calculate volume per label as voxel count multiplied with the image resolution.\n",
    "    \n",
    "    :param limg: Label image\n",
    "    :return: Label volumes\n",
    "    \"\"\"\n",
    "    # extract image resolution from header\n",
    "    vol_factor = np.round(limg.header.get_zooms(), 2).prod()\n",
    "\n",
    "    arr = limg.get_fdata()\n",
    "    labels = np.unique(arr)\n",
    "    volumes = {label: np.count_nonzero(arr[arr == label])*vol_factor for label in labels if label !=0}\n",
    "    return volumes\n",
    "\n",
    "\n",
    "def extract_int(img : nib.Nifti1Image, limg : nib.Nifti1Image) -> Tuple[Dict[int, np.ndarray], Dict[int, float]]:\n",
    "    \"\"\"Exract voxel intensities and mean intensity per label.\n",
    "    :param img: Intensity image\n",
    "    :param limg: Label image\n",
    "    :return: Dictionary with labels as keys and numpy.ndarrays containing voxel intensities as values and dictionary with labels as keys and mean intensity values as values\n",
    "    \"\"\"\n",
    "    arr = img.get_fdata()\n",
    "    larr = limg.get_fdata()\n",
    "    labels = np.unique(larr)\n",
    "    voxel_ints = {label: arr[larr == label] for label in labels if label !=0}\n",
    "    mean_int = {label: np.round(np.mean(values), 3) for label, values in voxel_ints.items()}\n",
    "    return voxel_ints, mean_int\n",
    "    \n",
    "\n",
    "def extract_features(imgs : Dict[str, nib.Nifti1Image], limgs : Dict[str, nib.Nifti1Image], return_vints : bool =False, label_dict : Dict[int, str] = {1: 'S1l', 2: 'S1r', 3: 'L5l', 4: 'L5r'}) -> pd.DataFrame:\n",
    "    \"\"\"Extract volume and intensity features from intensity-label-image-pair.\n",
    "    \n",
    "    :param imgs: Dictionary of image IDs and intensity images\n",
    "    :param limgs: Dictionary of image IDs and label images\n",
    "    :return_vints: Optional, if True return the voxel intensities of each label additional to the mean intensities, default: False\n",
    "    :label_dict: Optional, mapping of int label values to label strings, default: {1: 'S1l', 2: 'S1r', 3: 'L5l', 4: 'L5r'}\n",
    "    :return: Extracted features per image and label in tabular form\n",
    "    \"\"\"\n",
    "    dicts = []\n",
    "    for (img_id, img), (limg_id, limg) in zip(sorted(imgs.items()), sorted(limgs.items())):\n",
    "        # Check if the IDs of the intensity and label images match\n",
    "        if img_id == limg_id:\n",
    "            volumes = extract_vol(limg)\n",
    "            voxel_ints, mean_ints = extract_int(img, limg)\n",
    "            for (vlabel, vol), (milabel, mint), (vilabel, vints) in zip(volumes.items(), mean_ints.items(), voxel_ints.items()):\n",
    "                # Check if the labels of the volume, mean intensity, and voxel intensity entries match\n",
    "                if vlabel == milabel == vilabel:\n",
    "                    if return_vints:\n",
    "                        tmp_dict = dict(\n",
    "                                Sub_ID=img_id,\n",
    "                                Label=label_dict[vlabel],\n",
    "                                Volume=vol,\n",
    "                                VoxelInt=vints,\n",
    "                                MeanInt=mint,\n",
    "                            )\n",
    "                    else:\n",
    "                        tmp_dict = dict(\n",
    "                                Sub_ID=img_id,\n",
    "                                Label=label_dict[vlabel],\n",
    "                                Volume=vol,\n",
    "                                MeanInt=mint,\n",
    "                            )\n",
    "                    dicts.append(tmp_dict)\n",
    "                # Raise an error if the labels of the volume, mean intensity, and voxel intensity entries do not match\n",
    "                else:\n",
    "                    raise ValueError('Labels of volume and intensity entry do not match!')\n",
    "        # Raise an error if the IDs of the intensity and label images do not match   \n",
    "        else:\n",
    "            raise ValueError(f'IDs of intensity and label images do not match!\\n{img_id} <> {limg_id}')\n",
    "    \n",
    "    df = pd.DataFrame.from_records(dicts)\n",
    "    try:\n",
    "        df['Sub_ID'] = df.Sub_ID.astype(int)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_meta_info(df : pd.DataFrame, meta_df : pd.DataFrame, meta_keys: List):\n",
    "    \"\"\"Add meta information columns to a dataframe.\n",
    "    The meta information is added based on subject identifiers. Both dataframes must have a Sub_ID column.\n",
    "    The target dataframe and the mata information dataframe must not contain all identifiers. If the target \n",
    "    dataframe contains IDs not present in the meta information dataframe the cells will be filled with np.nan \n",
    "    values.\n",
    "    \n",
    "    :param df: Target dataframe, must have a Sub_ID column for mapping\n",
    "    :param meta_df: Dataframe containing meta information, must have a Sub_ID column for mapping\n",
    "    :param meta_keys: Names of meta information columns that should be added to the target dataframe\n",
    "    :return: Copy of the target dataframe with added meta information columns\n",
    "    \"\"\"\n",
    "    out_df = df.copy()\n",
    "    for key in meta_keys:\n",
    "        out_df[key] = np.nan\n",
    "        for row in df.iterrows():\n",
    "                out_df.loc[row[0], key] = meta_df[meta_df.Sub_ID==row[1].Sub_ID][key].item()\n",
    "    return out_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRG Feature calculation\n",
    "Execute the following cell to load the two testsets and calculate the label volumes and mean intensities for each image.<br>\n",
    "Input the path to the directory containing the testset directories.\n",
    "\n",
    "Testset directories must contain an images (intensity images, nifti files), model_predictions (label images, nifti files) and staple_gt (label images, nifti files) subdirectory as well as a metainformation.csv file.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = input('Path to directory containing test set subdirectories:\\n')\n",
    "\n",
    "# extract the features from the data set of healthy volunteers (HE)\n",
    "he_imgs = load_files(Path(data_dir, 'HE/images/'))\n",
    "he_pred = load_files(Path(data_dir, 'HE/model_predictions/DC-TopK'))\n",
    "he_gt = load_files(Path(data_dir, 'HE/staple_gt/'))\n",
    "he_fpred = extract_features(he_imgs, he_pred)\n",
    "he_fgt = extract_features(he_imgs, he_gt)\n",
    "\n",
    "# add meta information\n",
    "he_meta = pd.read_csv(Path(data_dir, 'HE/metainformation.csv'))\n",
    "he_fpred = add_meta_info(he_fpred, he_meta, ['Sex'])\n",
    "he_fgt = add_meta_info(he_fgt, he_meta, ['Sex'])\n",
    "\n",
    "# extract the features from the data set of FD patients (FD)\n",
    "fd_imgs = load_files(Path(data_dir, 'FD/images/'))\n",
    "fd_pred = load_files(Path(data_dir, 'FD/model_predictions/DC-TopK'))\n",
    "fd_gt = load_files(Path(data_dir, 'FD/staple_gt/'))\n",
    "fd_fpred = extract_features(fd_imgs, fd_pred)\n",
    "fd_fgt = extract_features(fd_imgs, fd_gt)\n",
    "\n",
    "# add meta information\n",
    "fd_meta = pd.read_csv(Path(data_dir, 'FD/metainformation.csv'))\n",
    "fd_fpred = add_meta_info(fd_fpred, fd_meta, ['Sex'])\n",
    "ref_fgt = add_meta_info(fd_fgt, fd_meta, ['Sex'])\n",
    "\n",
    "# stack into combined data frames\n",
    "fpred = pd.concat([he_fpred, fd_fpred], keys=['HE', 'FD']).reset_index(level=0, names='DataSet')\n",
    "fgt = pd.concat([he_fgt, fd_fgt], keys=['HE', 'FD']).reset_index(level=0, names='DataSet')\n",
    "\n",
    "print('DRG features predicted labels')\n",
    "display(fpred.head())\n",
    "print('\\nDRG features gt labels')\n",
    "display(fgt.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results as .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = input('Path to save directory:\\n')\n",
    "\n",
    "fpred.to_csv(Path(save_dir, 'DRG_features_pred.csv'))\n",
    "fgt.to_csv(Path(save_dir, 'DRG_features_gt.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "def multigrid_feature_correlation_pred_ref(\n",
    "        df_pred : pd.DataFrame, \n",
    "        df_gt : pd.DataFrame, \n",
    "        feature : str, \n",
    "        xlabel : str=None, \n",
    "        ylabel : str=None, \n",
    "        legend : bool=False, \n",
    "        axe_lim_dist : float = 10, \n",
    "        outlier_threshold : float = 2, \n",
    "        anno_pos : Tuple[int, int]=(500,390), \n",
    "        font_scale : float=1\n",
    "    ) -> sns.FacetGrid:\n",
    "    \"\"\"\n",
    "    Plots a scatter plot of the correlation between a feature in two datasets\n",
    "    with a regression line and excludes outliers based on a given threshold value.\n",
    "    \n",
    "    :param df_pred: Dataframe containing label features of one or multiple dataset (DataSet column required), calculated with predicted labels\n",
    "    :param df_gt: Dataframe containing label features of one or multiple dataset (DataSet column required), calculated with ground truth labels\n",
    "    :param feature: Name of a feature column\n",
    "    :param xlabel: Optional, change xlabel to value, if None derive from colum names, default: None\n",
    "    :param ylabel: Optional, change ylabel to value, if None derive from colum names, default: None\n",
    "    :param legend: Optional, if True show legend, default: False\n",
    "    :param axe_lim_dist: Optional, distance between biggest/smallest value and axe limits, default: 10\n",
    "    :param outlier_threshold: Optional, this value will be multiplied with the standard deviation to calculate a threshold value for exclusion of outliers, no thresholding if 0, default: 2\n",
    "    :param anno_pos: Optional, position of the annotation field, default: (500,390)\n",
    "    :param font_scale: Optional, font scaling factor, default: 1\n",
    "    :return: seaborn.FacetGrid object\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=font_scale)\n",
    "    sns.set_style('ticks')\n",
    "    # Combine into one df and clean outliers\n",
    "    if not xlabel:\n",
    "        xlabel = f'{feature}_ref'\n",
    "    if not ylabel:\n",
    "        ylabel = f'{feature}_pred'\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            df_pred.set_index('Sub_ID')[['DataSet',feature]].rename(columns={feature:ylabel}),\n",
    "            df_gt.set_index('Sub_ID')[feature].rename(xlabel, axis=0)\n",
    "        ], \n",
    "        axis=1\n",
    "    ).reset_index()\n",
    "\n",
    "    # Make grid\n",
    "    axe_lim = (data.min()[-2:].min() - axe_lim_dist, data.max()[-2:].max() + axe_lim_dist)\n",
    "    grid = sns.FacetGrid(\n",
    "        data=data, col='DataSet',\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        xlim=axe_lim,\n",
    "        ylim=axe_lim,\n",
    "        height=5,\n",
    "    )\n",
    "\n",
    "    # Add scatterplots\n",
    "    grid.map(sns.scatterplot, xlabel, ylabel, color='black', label=f'Data Points')\n",
    "    ax1, ax2 = grid.axes_dict['HE'], grid.axes_dict['FD']\n",
    "\n",
    "    if outlier_threshold:\n",
    "        corr = data[ylabel] / data[xlabel]\n",
    "        cleaned_data = data[\n",
    "            np.logical_and(\n",
    "                np.mean(corr) - outlier_threshold * np.std(corr)<corr,\n",
    "                corr<np.mean(corr) + outlier_threshold * np.std(corr)\n",
    "            )\n",
    "        ]\n",
    "        outliers = data.loc[data.index.difference(cleaned_data.index)]\n",
    "        outliers_sp1 = sns.scatterplot(\n",
    "            x=outliers[outliers.DataSet=='HE'][xlabel], \n",
    "            y=outliers[outliers.DataSet=='HE'][ylabel], \n",
    "            marker='o', edgecolor='black', linewidth=1, color='white',\n",
    "            ax=ax1,\n",
    "            label='Outliers',\n",
    "        )\n",
    "        outliers_sp2 = sns.scatterplot(\n",
    "            x=outliers[outliers.DataSet=='FD'][xlabel], \n",
    "            y=outliers[outliers.DataSet=='FD'][ylabel], \n",
    "            marker='o', edgecolor='black', linewidth=1, color='white',\n",
    "            ax=ax2,\n",
    "            label='Outliers',\n",
    "        )\n",
    "        reg_data = cleaned_data\n",
    "    else:\n",
    "        reg_data = data\n",
    "\n",
    "    # calc and add regression line\n",
    "    he_x = reg_data[reg_data.DataSet=='HE'][xlabel]\n",
    "    he_y = reg_data[reg_data.DataSet=='HE'][ylabel]\n",
    "    he_reg = stats.linregress(he_x, he_y)\n",
    "    regline1 = ax1.axline((0,he_reg.intercept), slope=he_reg.slope, color='black', alpha=0.5, label='Regression Line')\n",
    "    ax1.annotate(\n",
    "        f'y={np.round(he_reg.slope,2)}*x+{np.round(he_reg.intercept,2)}\\nPCC: {np.round(he_reg.rvalue,2)}'.replace('+-','-'), \n",
    "        xy=anno_pos,\n",
    "        xycoords='axes fraction',\n",
    "        bbox=dict(facecolor='none', edgecolor='black', boxstyle='round'),\n",
    "    )\n",
    "\n",
    "    fd_x = reg_data[reg_data.DataSet=='FD'][xlabel]\n",
    "    fd_y = reg_data[reg_data.DataSet=='FD'][ylabel]\n",
    "    fd_reg = stats.linregress(fd_x, fd_y)\n",
    "    regline2 = ax2.axline((0,fd_reg.intercept), slope=fd_reg.slope, color='black', alpha=0.5, label='Regression Line')\n",
    "    ax2.annotate(\n",
    "        f'y={np.round(fd_reg.slope,2)}*x+{np.round(fd_reg.intercept,2)}\\nPCC: {np.round(fd_reg.rvalue,2)}'.replace('+-','-'), \n",
    "        xy=anno_pos,\n",
    "        xycoords='axes fraction',\n",
    "        bbox=dict(facecolor='none', edgecolor='black', boxstyle='round'),\n",
    "    )\n",
    "\n",
    "    # add zero line\n",
    "    preg1 = ax1.axline((0, 0), slope=1, color='red', linestyle='--', alpha=0.5, label='PCC +1')\n",
    "    preg2 = ax2.axline((0, 0), slope=1, color='red', linestyle='--', alpha=0.5, label='PCC +1')\n",
    "\n",
    "    ax1.get_legend().remove()\n",
    "    ax2.get_legend().remove()\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    if legend:\n",
    "        grid.add_legend(dict(zip(labels, handles)))\n",
    "    return grid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to display the plots in a matplotlib pop-up window.<br>\n",
    "The window allows for manual modifications of border width etc. and saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to either execute the calculation cell above or load the results from a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpred = pd.read_csv('../data/feature_extraction/TestSet/DRG_features.csv')\n",
    "fgt = pd.read_csv('../data/feature_extraction/TestSet/reference_DRG_features.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Volume Correlation**\n",
    "For the paper figures the following attributes were adjusted in the pop-up window:\n",
    "- top=0.92\n",
    "- bottom=0.15\n",
    "- left=0.125\n",
    "- right=0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multigrid_feature_correlation_pred_ref(\n",
    "    fpred, fgt, 'Volume', \n",
    "    xlabel='Label Size GT [vx.]', ylabel='Label Size Pred. [vx.]', \n",
    "    axe_lim_dist= 50, outlier_threshold = 2, anno_pos=(0.42,0.05), font_scale=1.6, legend=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DRG Mean Signal Intensity Correlation**\n",
    "For the paper figures the following attributes were adjusted in the pop-up window:\n",
    "- top=0.92\n",
    "- bottom=0.15\n",
    "- left=0.1\n",
    "- right=0.98\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multigrid_feature_correlation_pred_ref(\n",
    "    fpred, fgt, 'MeanInt', \n",
    "    xlabel='Signal Intensity GT [a.u.]', ylabel='Signal Intensity Pred. [a.u.]', \n",
    "    outlier_threshold = 2, anno_pos=(0.55, 0.05), font_scale=1.4, legend=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DRG Mean Signal Intensity Comparison**\n",
    "For the paper figures the following attributes were adjusted in the pop-up window:\n",
    "- top=0.92\n",
    "- bottom=0.08\n",
    "- left=0.1\n",
    "- right=0.98\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new dataframe containing only males but both label types (gt, predicted)\n",
    "int_diff_male = pd.concat([fgt[fgt.Sex=='M'], fpred[fpred.Sex=='M']], keys=['GT', 'Prediction'], names=['Type']).reset_index(level='Type')\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('ticks')\n",
    "grid = sns.catplot(int_diff_male, x='DataSet', y='MeanInt', col='Type', kind='box', palette='Greys')\n",
    "grid.map(sns.stripplot, 'DataSet', 'MeanInt', marker='o', color='white', edgecolor='black', linewidth=1, alpha=0.7)\n",
    "grid.set_ylabels('DRG Mean Signal Intensity')\n",
    "grid.set_xlabels('Data Set')\n",
    "grid.set_titles('{col_name}')\n",
    "\n",
    "# Test for significant difference\n",
    "t_gt, p_gt = stats.ttest_ind(\n",
    "    int_diff_male[(int_diff_male['Type'] == 'GT') & (int_diff_male['DataSet'] == 'HE')]['MeanInt'].to_list(),\n",
    "    int_diff_male[(int_diff_male['Type'] == 'GT') & (int_diff_male['DataSet'] == 'FD')]['MeanInt'].to_list(),\n",
    "    equal_var=False,\n",
    ")\n",
    "t_pred, p_pred = stats.ttest_ind(\n",
    "    int_diff_male[(int_diff_male['Type'] == 'Prediction') & (int_diff_male['DataSet'] == 'HE')]['MeanInt'].to_list(),\n",
    "    int_diff_male[(int_diff_male['Type'] == 'Prediction') & (int_diff_male['DataSet'] == 'FD')]['MeanInt'].to_list(),\n",
    "    equal_var=False,\n",
    ")\n",
    "print(f'GT:         t-statistic: {t_gt}; p-value: {p_gt}\\nPrediction: t-statistic: {t_pred}; p-value: {p_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c86fd167394a4f75a14aa72f3d9242fb612dfabe6027dfb3bb945cf14260bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
